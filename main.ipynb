{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13feac6",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149876e",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0d0db04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Head:\n",
      "   Unnamed: 0        Date       Open       High        Low      Close  \\\n",
      "0           0  2015-01-02  14.858000  14.883333  14.217333  14.620667   \n",
      "1           1  2015-01-05  14.303333  14.433333  13.810667  14.006000   \n",
      "2           2  2015-01-06  14.004000  14.280000  13.614000  14.085333   \n",
      "3           3  2015-01-07  14.223333  14.318667  13.985333  14.063333   \n",
      "4           4  2015-01-08  14.187333  14.253333  14.000667  14.041333   \n",
      "\n",
      "     Volume  \n",
      "0  71466000  \n",
      "1  80527500  \n",
      "2  93928500  \n",
      "3  44526000  \n",
      "4  51637500  \n",
      "Dataset Shape:\n",
      "2274\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df= pd.read_csv('Dataset/Tasla_Stock_Updated_V2.csv')\n",
    "\n",
    "# Check the first few rows to confirm successful import\n",
    "print(\"Dataset Head:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"Dataset Shape:\")\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855689b9",
   "metadata": {},
   "source": [
    "### Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efbba541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values count: Unnamed: 0    0\n",
      "Date          0\n",
      "Open          0\n",
      "High          0\n",
      "Low           0\n",
      "Close         0\n",
      "Volume        0\n",
      "dtype: int64\n",
      "\n",
      "Total Missing Values: 0\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(f\"\\nMissing Values count: {missing_values}\")\n",
    "\n",
    "total_missing_values = missing_values.sum()\n",
    "print(f\"\\nTotal Missing Values: {total_missing_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f7b87",
   "metadata": {},
   "source": [
    "### Converting date to datetime format and selecting as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9b38fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after setting Date as index:\n",
      "            Unnamed: 0       Open       High        Low      Close    Volume\n",
      "Date                                                                        \n",
      "2015-01-02           0  14.858000  14.883333  14.217333  14.620667  71466000\n",
      "2015-01-05           1  14.303333  14.433333  13.810667  14.006000  80527500\n",
      "2015-01-06           2  14.004000  14.280000  13.614000  14.085333  93928500\n",
      "2015-01-07           3  14.223333  14.318667  13.985333  14.063333  44526000\n",
      "2015-01-08           4  14.187333  14.253333  14.000667  14.041333  51637500\n"
     ]
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"\\nDataset after setting Date as index:\")\n",
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ba844",
   "metadata": {},
   "source": [
    "### Splitting dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9de3b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = '2021-01-01'\n",
    "\n",
    "df_train_raw = df[df.index < split_date].copy()\n",
    "df_test_raw = df[df.index >= split_date].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbb2582",
   "metadata": {},
   "source": [
    "### Generalized function for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a05b8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df['Monthly_Return'] = df['Close'].pct_change() * 100\n",
    "    df['MA5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['MA10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['Volatility_5'] = df['Close'].rolling(window=5).std()\n",
    "    df['Volatility_10'] = df['Close'].rolling(window=10).std()\n",
    "    df['Volatility_20'] = df['Close'].rolling(window=20).std()\n",
    "    \n",
    "    df.dropna(inplace=True) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7919b4b",
   "metadata": {},
   "source": [
    "### Creating features for train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3be8eb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1138, 15)\n",
      "Test shape: (489, 15)\n",
      "Train head:\n",
      "             Unnamed: 0       Open       High        Low      Close     Volume  \\\n",
      "Date                                                                            \n",
      "2016-06-27         373  12.724000  13.254000  12.524667  13.236667  108081000   \n",
      "2016-06-28         374  13.459333  13.603333  13.294000  13.452667   93186000   \n",
      "2016-06-29         375  13.675333  14.118667  13.533333  14.012667   89923500   \n",
      "2016-06-30         376  14.198000  14.233333  13.934667  14.152000   72646500   \n",
      "2016-07-01         377  13.742667  14.549333  13.733333  14.433333   81000000   \n",
      "\n",
      "            Monthly_Return        MA5       MA10       MA20  Volatility_5  \\\n",
      "Date                                                                        \n",
      "2016-06-27        2.795752  13.391600  13.934200  14.418100      0.710143   \n",
      "2016-06-28        1.631835  13.154000  13.846400  14.346633      0.211251   \n",
      "2016-06-29        4.162739  13.334400  13.796334  14.315400      0.433364   \n",
      "2016-06-30        0.994341  13.546134  13.758667  14.293133      0.533249   \n",
      "2016-07-01        1.987938  13.857467  13.765534  14.284833      0.497924   \n",
      "\n",
      "            Volatility_10  Volatility_20  Volatility_50  Volatility_100  \n",
      "Date                                                                     \n",
      "2016-06-27       0.747453       0.773901       1.102792        1.896610  \n",
      "2016-06-28       0.747274       0.794528       1.079626        1.879786  \n",
      "2016-06-29       0.713641       0.794777       1.056934        1.846209  \n",
      "2016-06-30       0.679832       0.792698       1.023138        1.788887  \n",
      "2016-07-01       0.686943       0.790189       0.988021        1.728750  \n",
      "Test head:\n",
      "             Unnamed: 0        Open        High         Low       Close  \\\n",
      "Date                                                                     \n",
      "2022-02-03        1785  294.000000  312.333344  293.506653  297.046661   \n",
      "2022-02-04        1786  299.073334  312.166656  293.723328  307.773346   \n",
      "2022-02-07        1787  307.929993  315.923340  300.903320  302.446655   \n",
      "2022-02-08        1788  301.843323  308.763336  298.266663  307.333344   \n",
      "2022-02-09        1789  311.666656  315.423340  306.666656  310.666656   \n",
      "\n",
      "              Volume  Monthly_Return         MA5        MA10        MA20  \\\n",
      "Date                                                                       \n",
      "2022-02-03  78855600       -1.603250  300.741327  302.330997  324.898830   \n",
      "2022-02-04  73625400        3.611111  305.872662  301.644998  322.542497   \n",
      "2022-02-07  60994500       -1.730719  303.913995  300.889664  320.548830   \n",
      "2022-02-08  50729100        1.615719  303.297333  301.009665  318.280164   \n",
      "2022-02-09  52259400        1.084592  305.053333  300.829330  316.073497   \n",
      "\n",
      "            Volatility_5  Volatility_10  Volatility_20  Volatility_50  \\\n",
      "Date                                                                    \n",
      "2022-02-03     12.120968      13.341128      26.074153      27.828879   \n",
      "2022-02-04      6.296624      12.803806      25.339312      27.839196   \n",
      "2022-02-07      5.258390      12.474723      25.269841      27.860317   \n",
      "2022-02-08      4.418954      12.536388      24.246886      27.954749   \n",
      "2022-02-09      5.362086      12.365015      22.707753      27.469716   \n",
      "\n",
      "            Volatility_100  \n",
      "Date                        \n",
      "2022-02-03       46.188329  \n",
      "2022-02-04       45.579558  \n",
      "2022-02-07       45.042363  \n",
      "2022-02-08       44.476272  \n",
      "2022-02-09       43.896770  \n"
     ]
    }
   ],
   "source": [
    "df_train = create_features(df_train_raw)\n",
    "df_test = create_features(df_test_raw)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "print(\"Train head:\\n\", df_train.head())\n",
    "print(\"Test head:\\n\", df_test.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
